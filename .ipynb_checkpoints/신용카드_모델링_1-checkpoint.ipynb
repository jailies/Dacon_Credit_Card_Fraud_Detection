{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJu97PWEzUr5"
   },
   "source": [
    "## Import & Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "u8Wydav5x9tN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GnIphsrtyOfg"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-x0m-FjpyQsC"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "val_df = pd.read_csv('val.csv')\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "\n",
    "new_train_df = train_df[['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18']]\n",
    "new_val_df = val_df[['V2','V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18','Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbq_CpH8JHF-"
   },
   "source": [
    "## Method 1. GANomaly와 EllipticEnvelope를 이용한 Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL4Iotloz_Hp"
   },
   "source": [
    "## GANomaly\n",
    "\n",
    "*   GANomaly는 semi-supervised 이상치 탐지에 사용되는 모델입니다\n",
    "\n",
    "*   기존의 AnoGAN에 비해 Encoder 부분이 추가 됨으로써 latent vector를 두 번 생성하여 loss를 한 번 더 계산해주어 정확도를 높인다는 점이 장점이라 할 수 있습니다다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYKQNLcZzP0z",
    "outputId": "baa36494-9738-4eda-ef88-6f12badb29b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-la-0m4qyZdK"
   },
   "outputs": [],
   "source": [
    "LR = 1e-2\n",
    "batch_size = 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NsSOLAKLyaDd"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, eval_mode):\n",
    "        self.df = df\n",
    "        self.eval_mode = eval_mode\n",
    "        if self.eval_mode:\n",
    "            self.labels = self.df['Class'].values\n",
    "            self.df = self.df.drop(columns=['Class']).values\n",
    "        else:\n",
    "            self.df = self.df.values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.eval_mode:\n",
    "            self.x = self.df[index]\n",
    "            self.y = self.labels[index]\n",
    "            return torch.Tensor(self.x), self.y\n",
    "        else:\n",
    "            self.x = self.df[index]\n",
    "            return torch.Tensor(self.x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gD_Y2Zj9y5v4"
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df=train_df, eval_mode=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = MyDataset(df = val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8JxtYSTcy8JG"
   },
   "outputs": [],
   "source": [
    "class GANnomaly(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.encoder = Encoder().to(device)\n",
    "        self.decoder = Decoder().to(device)\n",
    "        self.discriminator = Discriminator().to(device)\n",
    "        \n",
    "        self.models = [self.encoder, self.decoder, self.discriminator]   \n",
    "                \n",
    "        self.params = None\n",
    "        for idx_m, model in enumerate(self.models):\n",
    "            if (self.params is None):\n",
    "                self.params = list(model.parameters())\n",
    "            else:\n",
    "                self.params = self.params + list(model.parameters())\n",
    "                \n",
    "        self.optimizer = optim.Adam(self.params, lr=0.0001)\n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(30,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        z_code = self.encoder(x)\n",
    "\n",
    "        return z_code\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(64,30),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x_hat = self.decoder(x)\n",
    "\n",
    "        return x_hat\n",
    "    \n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.dis_dense = nn.ModuleList([\n",
    "            nn.Linear(30, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Sigmoid(),\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        featurebank = []\n",
    "        \n",
    "        for idx, layer in enumerate(self.dis_dense):\n",
    "            x = layer(x)\n",
    "            if(\"torch.nn.modules.activation\" in str(type(layer))):\n",
    "                featurebank.append(x)\n",
    "        disc_score = x\n",
    "\n",
    "        return disc_score, featurebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uSRdJRPm0aw9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def loss_enc(z_code, z_code_hat):\n",
    "\n",
    "    l_enc = torch.sum((z_code - z_code_hat)**2, dim=(1))\n",
    "\n",
    "    return l_enc\n",
    "\n",
    "def loss_rec(x, x_hat):\n",
    "    l_con = torch.sum(torch.abs(x - x_hat), dim=(1))\n",
    "\n",
    "    return l_con\n",
    "\n",
    "def loss_adv(dis_x, dis_x_hat, features_real, features_fake):\n",
    "\n",
    "    l_adv = torch.sum((dis_x - dis_x_hat)**2, dim=(1))\n",
    "\n",
    "\n",
    "    for fidx, _ in enumerate(features_real):\n",
    "        \n",
    "        l_adv += torch.sum((features_real[fidx] - features_fake[fidx])**2, dim=(1))\n",
    "            \n",
    "    return l_adv\n",
    "\n",
    "\n",
    "def loss_gan(z_code, z_code_hat, x, x_hat,\n",
    "    dis_x, dis_x_hat, features_real, features_fake,\n",
    "    w_enc=1, w_con=50, w_adv=1):\n",
    "    \n",
    "\n",
    "    z_code, z_code_hat, x, x_hat = z_code, z_code_hat, x, x_hat\n",
    "\n",
    "    for fidx, _ in enumerate(features_real):\n",
    "        features_real[fidx] = features_real[fidx]\n",
    "        features_fake[fidx] = features_fake[fidx]\n",
    "        \n",
    "    l_enc = loss_enc(z_code, z_code_hat)\n",
    "    l_con = loss_rec(x, x_hat)\n",
    "    l_adv = loss_adv(dis_x, dis_x_hat, features_real, features_fake)\n",
    "\n",
    "\n",
    "    l_tot = torch.mean((w_enc * l_enc) + (w_con * l_con) + (w_adv * l_adv))\n",
    "    \n",
    "    l_enc = torch.mean(l_enc)\n",
    "    l_con = torch.mean(l_con)\n",
    "    l_adv = torch.mean(l_adv)\n",
    "\n",
    "\n",
    "    return l_tot, l_enc, l_con, l_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlDX_9Mjy-mr",
    "outputId": "f2c3bf78-c4f3-48c7-a730-e117548ca0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train loss : [1439.7182791573662] Val Score : [0.0010529271374420891])\n",
      "Epoch : [2] Train loss : [1076.1747000558037] Val Score : [0.0010529271374420891])\n",
      "Epoch : [3] Train loss : [1040.8084193638392] Val Score : [0.0010529271374420891])\n",
      "Epoch : [4] Train loss : [1013.7720685686384] Val Score : [0.0010529271374420891])\n",
      "Epoch : [5] Train loss : [991.4998343331473] Val Score : [0.0010529271374420891])\n",
      "Epoch : [6] Train loss : [971.6981462751116] Val Score : [0.0010529271374420891])\n",
      "Epoch : [7] Train loss : [953.4087350027902] Val Score : [0.0010529271374420891])\n",
      "Epoch : [8] Train loss : [935.6685006277902] Val Score : [0.0010529271374420891])\n",
      "Epoch : [9] Train loss : [918.1640625] Val Score : [0.0010529271374420891])\n",
      "Epoch : [10] Train loss : [900.4549211774554] Val Score : [0.0010529271374420891])\n",
      "Epoch : [11] Train loss : [882.2840663364956] Val Score : [0.0010529271374420891])\n",
      "Epoch : [12] Train loss : [863.6807512555804] Val Score : [0.0010529271374420891])\n",
      "Epoch 00012: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch : [13] Train loss : [848.6002720424107] Val Score : [0.0010529271374420891])\n",
      "Epoch : [14] Train loss : [838.6957484654018] Val Score : [0.0010529271374420891])\n",
      "Epoch : [15] Train loss : [828.61669921875] Val Score : [0.0010529271374420891])\n",
      "Epoch : [16] Train loss : [818.2102573939732] Val Score : [0.0010529271374420891])\n",
      "Epoch : [17] Train loss : [807.5600847516741] Val Score : [0.0010529271374420891])\n",
      "Epoch : [18] Train loss : [796.9357822963169] Val Score : [0.0010529271374420891])\n",
      "Epoch : [19] Train loss : [786.0137677873884] Val Score : [0.001158541795224466])\n",
      "Epoch : [20] Train loss : [775.0135585239956] Val Score : [0.0024241852645348933])\n",
      "Epoch : [21] Train loss : [763.7559901646206] Val Score : [0.0029505945542486044])\n",
      "Epoch : [22] Train loss : [752.4855172293527] Val Score : [0.0036516136556133914])\n",
      "Epoch : [23] Train loss : [741.214338030134] Val Score : [0.004666349574572634])\n",
      "Epoch : [24] Train loss : [729.7739345005581] Val Score : [0.0061671753547908135])\n",
      "Epoch : [25] Train loss : [718.479265485491] Val Score : [0.007524497349255932])\n",
      "Epoch : [26] Train loss : [707.1971871512277] Val Score : [0.009016759339565604])\n",
      "Epoch : [27] Train loss : [696.1034894670759] Val Score : [0.010780869461823713])\n",
      "Epoch : [28] Train loss : [685.1804460797991] Val Score : [0.012469918393735558])\n",
      "Epoch : [29] Train loss : [674.2507847377232] Val Score : [0.014872907836955175])\n",
      "Epoch : [30] Train loss : [663.6028703962054] Val Score : [0.018115546354090985])\n",
      "Epoch : [31] Train loss : [652.969220842634] Val Score : [0.02180996585326589])\n",
      "Epoch : [32] Train loss : [642.4053344726562] Val Score : [0.027450229985789273])\n",
      "Epoch : [33] Train loss : [631.8860822405134] Val Score : [0.03424560629750537])\n",
      "Epoch : [34] Train loss : [621.3391200474331] Val Score : [0.04049240920827315])\n",
      "Epoch : [35] Train loss : [610.7089146205357] Val Score : [0.047588756773507324])\n",
      "Epoch : [36] Train loss : [600.0841936383929] Val Score : [0.055086008316156086])\n",
      "Epoch : [37] Train loss : [589.353288922991] Val Score : [0.06348968065682473])\n",
      "Epoch : [38] Train loss : [578.6182425362723] Val Score : [0.07329501884884435])\n",
      "Epoch : [39] Train loss : [567.8135550362723] Val Score : [0.08366988782620136])\n",
      "Epoch : [40] Train loss : [557.1055559430804] Val Score : [0.09439606727566913])\n",
      "Epoch : [41] Train loss : [546.3881312779018] Val Score : [0.106937014271714])\n",
      "Epoch : [42] Train loss : [535.713849748884] Val Score : [0.12197965849336308])\n",
      "Epoch : [43] Train loss : [525.0032871791294] Val Score : [0.13787611095724617])\n",
      "Epoch : [44] Train loss : [514.4843314034598] Val Score : [0.15497263653199106])\n",
      "Epoch : [45] Train loss : [503.9122532435826] Val Score : [0.1734683810350925])\n",
      "Epoch : [46] Train loss : [493.4122750418527] Val Score : [0.19175747181956884])\n",
      "Epoch : [47] Train loss : [483.04163033621654] Val Score : [0.21114006444459638])\n",
      "Epoch : [48] Train loss : [472.784432547433] Val Score : [0.22945773306145106])\n",
      "Epoch : [49] Train loss : [462.57606288364957] Val Score : [0.24838050006173087])\n",
      "Epoch : [50] Train loss : [452.5904976981027] Val Score : [0.2650914052287454])\n",
      "Epoch : [51] Train loss : [442.7470136369978] Val Score : [0.28185990459996085])\n",
      "Epoch : [52] Train loss : [433.1583905901228] Val Score : [0.29818040278374436])\n",
      "Epoch : [53] Train loss : [423.7057364327567] Val Score : [0.31472467054334435])\n",
      "Epoch : [54] Train loss : [414.59423392159596] Val Score : [0.32893011252154397])\n",
      "Epoch : [55] Train loss : [405.7940194266183] Val Score : [0.34115845190327143])\n",
      "Epoch : [56] Train loss : [397.3059605189732] Val Score : [0.3523078621996351])\n",
      "Epoch : [57] Train loss : [389.08532278878346] Val Score : [0.3624998628528795])\n",
      "Epoch : [58] Train loss : [381.2409362792969] Val Score : [0.3719579919482349])\n",
      "Epoch : [59] Train loss : [373.6442304338728] Val Score : [0.38153275086924937])\n",
      "Epoch : [60] Train loss : [366.22559029715404] Val Score : [0.38967948220013815])\n",
      "Epoch : [61] Train loss : [359.0283682686942] Val Score : [0.3975460836106613])\n",
      "Epoch : [62] Train loss : [352.1042000906808] Val Score : [0.40530358778419834])\n",
      "Epoch : [63] Train loss : [345.2168622698103] Val Score : [0.41287077003956724])\n",
      "Epoch : [64] Train loss : [338.7300763811384] Val Score : [0.42026104722461877])\n",
      "Epoch : [65] Train loss : [332.3048793247768] Val Score : [0.4269672647482206])\n",
      "Epoch : [66] Train loss : [326.1355983189174] Val Score : [0.4334235400590803])\n",
      "Epoch : [67] Train loss : [320.15638950892856] Val Score : [0.43936558745490895])\n",
      "Epoch : [68] Train loss : [314.239990234375] Val Score : [0.444903319002985])\n",
      "Epoch : [69] Train loss : [308.48907470703125] Val Score : [0.44907016236975916])\n",
      "Epoch : [70] Train loss : [302.90417916434154] Val Score : [0.45293987630888033])\n",
      "Epoch : [71] Train loss : [297.42972673688615] Val Score : [0.4564874347202097])\n",
      "Epoch : [72] Train loss : [292.05110822405135] Val Score : [0.46010333790815516])\n",
      "Epoch : [73] Train loss : [286.77637154715404] Val Score : [0.46342424820395445])\n",
      "Epoch : [74] Train loss : [281.5292489188058] Val Score : [0.46646750866700504])\n",
      "Epoch : [75] Train loss : [276.46175275530135] Val Score : [0.4697080595081973])\n",
      "Epoch : [76] Train loss : [271.506356375558] Val Score : [0.47242277889169765])\n",
      "Epoch : [77] Train loss : [266.62986973353793] Val Score : [0.47512217771199305])\n",
      "Epoch : [78] Train loss : [261.7385689871652] Val Score : [0.47790109275458703])\n",
      "Epoch : [79] Train loss : [256.99510410853793] Val Score : [0.48073819142155094])\n",
      "Epoch : [80] Train loss : [252.26996721540178] Val Score : [0.4833672647142932])\n",
      "Epoch : [81] Train loss : [247.6429922921317] Val Score : [0.4855041882198643])\n",
      "Epoch : [82] Train loss : [243.13743373325892] Val Score : [0.48777246657139584])\n",
      "Epoch : [83] Train loss : [238.7004111153739] Val Score : [0.4897964214855636])\n",
      "Epoch : [84] Train loss : [234.38992963518416] Val Score : [0.491645383478272])\n",
      "Epoch : [85] Train loss : [230.17375837053572] Val Score : [0.49339691497521876])\n",
      "Epoch : [86] Train loss : [226.15113176618303] Val Score : [0.4944047231572876])\n",
      "Epoch : [87] Train loss : [222.31532287597656] Val Score : [0.49568373449662484])\n",
      "Epoch : [88] Train loss : [218.7174072265625] Val Score : [0.49682323033875825])\n",
      "Epoch : [89] Train loss : [215.2820085797991] Val Score : [0.49806684557666153])\n",
      "Epoch : [90] Train loss : [212.0907701764788] Val Score : [0.4989850979779271])\n",
      "Epoch : [91] Train loss : [209.09969220842635] Val Score : [0.49974875530853613])\n",
      "Epoch : [92] Train loss : [206.23165239606584] Val Score : [0.5004570504335523])\n",
      "Epoch : [93] Train loss : [203.5143824986049] Val Score : [0.5011626239321569])\n",
      "Epoch : [94] Train loss : [200.93416704450334] Val Score : [0.5019038090603355])\n",
      "Epoch : [95] Train loss : [198.47808619907923] Val Score : [0.5024865330577507])\n",
      "Epoch : [96] Train loss : [196.08104814801897] Val Score : [0.5032414950484649])\n",
      "Epoch : [97] Train loss : [193.7917698451451] Val Score : [0.503708163582226])\n",
      "Epoch : [98] Train loss : [191.54957798549108] Val Score : [0.5041825891765471])\n",
      "Epoch : [99] Train loss : [189.48436628069197] Val Score : [0.5046651501082147])\n",
      "Epoch : [100] Train loss : [187.45691789899553] Val Score : [0.5049416518061809])\n",
      "Epoch : [101] Train loss : [185.48607308523995] Val Score : [0.5052858185515415])\n",
      "Epoch : [102] Train loss : [183.58753967285156] Val Score : [0.5058987795198697])\n",
      "Epoch : [103] Train loss : [181.6952383858817] Val Score : [0.5064129486964104])\n",
      "Epoch : [104] Train loss : [179.86625017438615] Val Score : [0.5070757950116161])\n",
      "Epoch : [105] Train loss : [178.103999546596] Val Score : [0.5075664862314123])\n",
      "Epoch : [106] Train loss : [176.34026227678572] Val Score : [0.5080666648195433])\n",
      "Epoch : [107] Train loss : [174.62289210728235] Val Score : [0.5083569226104104])\n",
      "Epoch : [108] Train loss : [172.91685485839844] Val Score : [0.5088978221473411])\n",
      "Epoch : [109] Train loss : [171.21945190429688] Val Score : [0.5097059233701152])\n",
      "Epoch : [110] Train loss : [169.5589359828404] Val Score : [0.5101461232666105])\n",
      "Epoch : [111] Train loss : [167.9202423095703] Val Score : [0.5107009582598172])\n",
      "Epoch : [112] Train loss : [166.34598432268416] Val Score : [0.5110508207009282])\n",
      "Epoch : [113] Train loss : [164.77002825055803] Val Score : [0.5115436819909746])\n",
      "Epoch : [114] Train loss : [163.25572422572546] Val Score : [0.5125029298727024])\n",
      "Epoch : [115] Train loss : [161.67251804896765] Val Score : [0.513115117654691])\n",
      "Epoch : [116] Train loss : [160.15079607282365] Val Score : [0.5138041346387675])\n",
      "Epoch : [117] Train loss : [158.65249633789062] Val Score : [0.5145764775751472])\n",
      "Epoch : [118] Train loss : [157.1956525530134] Val Score : [0.5151486303989417])\n",
      "Epoch : [119] Train loss : [155.76261465890067] Val Score : [0.5161342840048434])\n",
      "Epoch : [120] Train loss : [154.34261648995536] Val Score : [0.5169885639106235])\n",
      "Epoch : [121] Train loss : [152.93048967633928] Val Score : [0.5178030731719908])\n",
      "Epoch : [122] Train loss : [151.568115234375] Val Score : [0.5192910867962949])\n",
      "Epoch : [123] Train loss : [150.24564906529017] Val Score : [0.520798418938062])\n",
      "Epoch : [124] Train loss : [148.91908700125558] Val Score : [0.5221477592793243])\n",
      "Epoch : [125] Train loss : [147.6286163330078] Val Score : [0.5240922689568898])\n",
      "Epoch : [126] Train loss : [146.3961465018136] Val Score : [0.5264175782959509])\n",
      "Epoch : [127] Train loss : [145.1283700125558] Val Score : [0.528477313683947])\n",
      "Epoch : [128] Train loss : [143.92095511300224] Val Score : [0.5316736886392187])\n",
      "Epoch : [129] Train loss : [142.70931788853235] Val Score : [0.5340321199222899])\n",
      "Epoch : [130] Train loss : [141.55047607421875] Val Score : [0.5367842009326989])\n",
      "Epoch : [131] Train loss : [140.39969744001115] Val Score : [0.5389894609401439])\n",
      "Epoch : [132] Train loss : [139.2745404924665] Val Score : [0.5412036648612704])\n",
      "Epoch : [133] Train loss : [138.12604413713728] Val Score : [0.5430121488132839])\n",
      "Epoch : [134] Train loss : [137.0782710484096] Val Score : [0.5443189926328554])\n",
      "Epoch : [135] Train loss : [135.95543125697546] Val Score : [0.54536585119794])\n",
      "Epoch : [136] Train loss : [134.8854718889509] Val Score : [0.5468967903812862])\n",
      "Epoch : [137] Train loss : [133.87750462123327] Val Score : [0.548391907358596])\n",
      "Epoch : [138] Train loss : [132.80328369140625] Val Score : [0.549593983849242])\n",
      "Epoch : [139] Train loss : [131.85218920026506] Val Score : [0.550088207505037])\n",
      "Epoch : [140] Train loss : [130.86417715890067] Val Score : [0.5513590165877261])\n",
      "Epoch : [141] Train loss : [129.91614968436105] Val Score : [0.5540635212673894])\n",
      "Epoch : [142] Train loss : [128.97066061837333] Val Score : [0.5556525296376691])\n",
      "Epoch : [143] Train loss : [128.12242453438895] Val Score : [0.5571658045217939])\n",
      "Epoch : [144] Train loss : [127.24513789585659] Val Score : [0.5594039699950464])\n",
      "Epoch : [145] Train loss : [126.36718205043248] Val Score : [0.5612692094416567])\n",
      "Epoch : [146] Train loss : [125.52355412074498] Val Score : [0.5628713921901528])\n",
      "Epoch : [147] Train loss : [124.73711177280971] Val Score : [0.5641682994348549])\n",
      "Epoch : [148] Train loss : [123.89061846051898] Val Score : [0.5661035992102532])\n",
      "Epoch : [149] Train loss : [123.11238752092633] Val Score : [0.5679345323877522])\n",
      "Epoch : [150] Train loss : [122.30701119559151] Val Score : [0.5692054548941593])\n",
      "Epoch : [151] Train loss : [121.51309749058315] Val Score : [0.5723410221437316])\n",
      "Epoch : [152] Train loss : [120.75890568324498] Val Score : [0.5732838152882681])\n",
      "Epoch : [153] Train loss : [119.9981689453125] Val Score : [0.5749877626356633])\n",
      "Epoch : [154] Train loss : [119.21949332101005] Val Score : [0.5780807278252873])\n",
      "Epoch : [155] Train loss : [118.50341142926898] Val Score : [0.5808400645805448])\n",
      "Epoch : [156] Train loss : [117.75890568324498] Val Score : [0.5819941457534832])\n",
      "Epoch : [157] Train loss : [117.05843026297433] Val Score : [0.5847044184696032])\n",
      "Epoch : [158] Train loss : [116.30889020647321] Val Score : [0.5892638238382694])\n",
      "Epoch : [159] Train loss : [115.58289664132255] Val Score : [0.5931774344958539])\n",
      "Epoch : [160] Train loss : [114.86751883370536] Val Score : [0.5970231897402684])\n",
      "Epoch : [161] Train loss : [114.23845781598773] Val Score : [0.6003206024907184])\n",
      "Epoch : [162] Train loss : [113.47813742501395] Val Score : [0.6029354027598012])\n",
      "Epoch : [163] Train loss : [112.80365535191127] Val Score : [0.6071081826004132])\n",
      "Epoch : [164] Train loss : [112.10975864955357] Val Score : [0.6126650827260689])\n",
      "Epoch : [165] Train loss : [111.47017233712333] Val Score : [0.6170639846778195])\n",
      "Epoch : [166] Train loss : [110.83746991838727] Val Score : [0.6199839985046101])\n",
      "Epoch : [167] Train loss : [110.20019640241351] Val Score : [0.6269271222469763])\n",
      "Epoch : [168] Train loss : [109.53039441789899] Val Score : [0.637743393329887])\n",
      "Epoch : [169] Train loss : [108.87607792445591] Val Score : [0.6451328074678382])\n",
      "Epoch : [170] Train loss : [108.2204121180943] Val Score : [0.6477699861394978])\n",
      "Epoch : [171] Train loss : [107.58856746128627] Val Score : [0.6523788313564907])\n",
      "Epoch : [172] Train loss : [107.01031821114677] Val Score : [0.6562726057501772])\n",
      "Epoch : [173] Train loss : [106.35936192103794] Val Score : [0.66357535404777])\n",
      "Epoch : [174] Train loss : [105.77526092529297] Val Score : [0.6777789518174134])\n",
      "Epoch : [175] Train loss : [105.23760005405971] Val Score : [0.687239175221426])\n",
      "Epoch : [176] Train loss : [104.60911778041294] Val Score : [0.6901265786034538])\n",
      "Epoch : [177] Train loss : [104.00448063441685] Val Score : [0.7059866032567539])\n",
      "Epoch : [178] Train loss : [103.4567402430943] Val Score : [0.7112658784551884])\n",
      "Epoch : [179] Train loss : [102.85905020577567] Val Score : [0.714936337281296])\n",
      "Epoch : [180] Train loss : [102.27980259486607] Val Score : [0.7168192118976862])\n",
      "Epoch : [181] Train loss : [101.71786499023438] Val Score : [0.7187349645015549])\n",
      "Epoch : [182] Train loss : [101.19041333879743] Val Score : [0.7226686263465465])\n",
      "Epoch : [183] Train loss : [100.647705078125] Val Score : [0.7226686263465465])\n",
      "Epoch : [184] Train loss : [100.11819131033761] Val Score : [0.7226686263465465])\n",
      "Epoch : [185] Train loss : [99.5890873500279] Val Score : [0.7226686263465465])\n",
      "Epoch : [186] Train loss : [99.03704833984375] Val Score : [0.7246883762645999])\n",
      "Epoch : [187] Train loss : [98.54044669015067] Val Score : [0.7288385690883094])\n",
      "Epoch : [188] Train loss : [98.00992911202567] Val Score : [0.7288385690883094])\n",
      "Epoch : [189] Train loss : [97.48646000453404] Val Score : [0.7288385690883094])\n",
      "Epoch : [190] Train loss : [96.95380292619977] Val Score : [0.7353562550268086])\n",
      "Epoch : [191] Train loss : [96.47766767229352] Val Score : [0.7376112450647377])\n",
      "Epoch : [192] Train loss : [95.96824645996094] Val Score : [0.7376112450647377])\n",
      "Epoch : [193] Train loss : [95.50377328055245] Val Score : [0.7399094305905288])\n",
      "Epoch : [194] Train loss : [95.0436782836914] Val Score : [0.7399094305905288])\n",
      "Epoch : [195] Train loss : [94.51195417131696] Val Score : [0.7399094305905288])\n",
      "Epoch : [196] Train loss : [94.06523132324219] Val Score : [0.7399094305905288])\n",
      "Epoch : [197] Train loss : [93.56503186907086] Val Score : [0.7399094305905288])\n",
      "Epoch : [198] Train loss : [93.08639090401786] Val Score : [0.7422520697342344])\n",
      "Epoch : [199] Train loss : [92.65406908307757] Val Score : [0.7422520697342344])\n",
      "Epoch : [200] Train loss : [92.20315442766461] Val Score : [0.7422520697342344])\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "model = GANnomaly()\n",
    "model.encoder.train()\n",
    "model.decoder.train()\n",
    "model.discriminator.train()\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(model.optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "for i in range(1,epochs+1) :\n",
    "        \n",
    "    train_loss = []\n",
    "    best_score = 0\n",
    "\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        \n",
    "        x = data.to(device)\n",
    "        \n",
    "        z_code = model.encoder(x)\n",
    "        x_hat = model.decoder(z_code)\n",
    "        z_code_hat = model.encoder(x_hat)\n",
    "        \n",
    "        dis_x, features_real = model.discriminator(x)\n",
    "        dis_x_hat, features_fake = model.discriminator(x_hat)\n",
    "        \n",
    "\n",
    "        l_tot, l_enc, l_con, l_adv = loss_gan(z_code, z_code_hat, \n",
    "                                       x, x_hat, \n",
    "                                       dis_x, dis_x_hat, \n",
    "                                       features_real, features_fake)\n",
    "\n",
    "        model.optimizer.zero_grad()\n",
    "        l_tot.backward()\n",
    "        model.optimizer.step()\n",
    "        \n",
    "        train_loss.append(l_tot.item())\n",
    "    \n",
    "    #validation\n",
    "    model.encoder.eval()\n",
    "    model.decoder.eval()\n",
    "    \n",
    "    pred = []\n",
    "    true = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in iter(val_loader):\n",
    "            x = x.float().to(device)\n",
    "\n",
    "            _x = model.decoder(model.encoder(x))\n",
    "            diff = cos(x, _x).cpu().tolist()\n",
    "            batch_pred = np.where(np.array(diff) < 0.95, 1,0).tolist()\n",
    "            pred += batch_pred\n",
    "            true += y.tolist()\n",
    "        \n",
    "        score = f1_score(true, pred, average='macro')\n",
    "    \n",
    "    \n",
    "    print(f'Epoch : [{i}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
    "\n",
    "\n",
    "    scheduler.step(score)\n",
    "\n",
    "    if best_score < score:\n",
    "        best_score = score\n",
    "        torch.save(model.encoder.state_dict(), 'best_encoder.pth', _use_new_zipfile_serialization=False)\n",
    "        torch.save(model.decoder.state_dict(), 'best_decoder.pth', _use_new_zipfile_serialization=False)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdFdaj8gzBBV",
    "outputId": "827a7f9a-671a-43fb-ad2e-f781aa2a2bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Linear(in_features=64, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GANnomaly()\n",
    "model.encoder.load_state_dict(torch.load('best_encoder.pth'))\n",
    "model.decoder.load_state_dict(torch.load('best_decoder.pth'))\n",
    "model.encoder.eval()\n",
    "model.decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "H3t6zM3DzCyn"
   },
   "outputs": [],
   "source": [
    "val_dataset = MyDataset(df = val_df, eval_mode=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "n_8IzryOzFkj"
   },
   "outputs": [],
   "source": [
    "model.encoder.eval()\n",
    "model.decoder.eval()\n",
    "val_sim = np.zeros(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in val_loader:\n",
    "        data, target = data.to(device), data.cpu()\n",
    "        output = model.decoder(model.encoder(data))\n",
    "        output = output.reshape(-1,30).cpu()\n",
    "        target = target.reshape(-1,30)\n",
    "        val_sim = np.append(val_sim, cos(output,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfCu-WQ2zGYu",
    "outputId": "7f4461a6-153a-49ec-9f9a-07377225c4bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9066829407144783\n",
      "[[28427     5]\n",
      " [    6    24]]\n"
     ]
    }
   ],
   "source": [
    "thr = 0.814\n",
    "\n",
    "pred_GAN = np.where(val_sim < thr,1,0)\n",
    "\n",
    "print(f1_score(pred_GAN,val_df['Class'],average='macro'))\n",
    "print(confusion_matrix(val_df['Class'],pred_GAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDIamu7czLLY",
    "outputId": "f4c5068c-cc51-456b-c217-9294147690d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.83      0.80      0.81        30\n",
      "\n",
      "    accuracy                           1.00     28462\n",
      "   macro avg       0.91      0.90      0.91     28462\n",
      "weighted avg       1.00      1.00      1.00     28462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_df['Class'],pred_GAN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hZpagLd-gbt"
   },
   "source": [
    "## EllipticEnvelope\n",
    "\n",
    "*   사이킷런에서 제공하는 공분산 추정을 할 수 있는 객체입니다\n",
    "\n",
    "*   데이터의 모양을 정의하는데, 중심 데이터에 타원을 맞추고 그 바깥의 점을 무시하는 방식입니다\n",
    "\n",
    "*   인라이어 데이터가 정규 분포를 이룬다고 가정하면 인라이어 위치와 분산을 추정할 수 있고 이를 토대로 Mahalanobis 거리를 얻어 아웃라이어를 추정합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXKqCv1u-vYf",
    "outputId": "a8c49ebd-36a4-4b46-8b09-6a72264b4cc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010540369615627855"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = val_df['Class'].sum()/len(val_df)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27uBVtGO-pA5",
    "outputId": "ca58e8a0-8637-4221-8e92-5a529d201945"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EllipticEnvelope(contamination=0.0010540369615627855, random_state=2022,\n",
       "                 support_fraction=0.994)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EE = EllipticEnvelope(support_fraction = 0.994, contamination = ratio, random_state = 2022)\n",
    "EE.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uoUzXTE-zF8",
    "outputId": "0735db41-6df5-4e03-a5d5-4efc288d4c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score : [0.9236496787663914]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.86      0.83      0.85        30\n",
      "\n",
      "    accuracy                           1.00     28462\n",
      "   macro avg       0.93      0.92      0.92     28462\n",
      "weighted avg       1.00      1.00      1.00     28462\n",
      "\n",
      "[[28428     4]\n",
      " [    5    25]]\n"
     ]
    }
   ],
   "source": [
    "def get_pred_label_EE(model, x, k):\n",
    "    prob = model.score_samples(x)\n",
    "    prob = torch.tensor(prob, dtype = torch.float)\n",
    "    topk_indices = torch.topk(prob, k = k, largest = False).indices\n",
    "\n",
    "    pred = torch.zeros(len(x), dtype = torch.long)\n",
    "    pred[topk_indices] = 1\n",
    "    return pred.tolist(), prob.tolist()\n",
    "\n",
    "val_x = val_df.drop(columns= 'Class') # Input Data\n",
    "val_y = val_df['Class'] # Label\n",
    "\n",
    "pred_EE, prob = get_pred_label_EE(EE, val_x, 29)\n",
    "val_score = f1_score(val_y, pred_EE, average='macro')\n",
    "print(f'Validation F1 Score : [{val_score}]')\n",
    "print(classification_report(val_y, pred_EE))\n",
    "print(confusion_matrix(val_y, pred_EE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEzMsKzVBO7D"
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "CbhEVVhPBFX1"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def mode (x) :\n",
    "    cnt = Counter(x)\n",
    "    mode = cnt.most_common(1)\n",
    "    return mode[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SqkNfBn1BHZw"
   },
   "outputs": [],
   "source": [
    "def get_ensemble_pred (x,) :\n",
    "    # pred GAN\n",
    "    test_dataset = MyDataset(x, False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    test_sim = np.zeros(0)\n",
    "    print('start')\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data, target = data.to(device), data.cpu()\n",
    "            output = model.decoder(model.encoder(data))\n",
    "            output = output.reshape(-1,30).cpu()\n",
    "            target = target.reshape(-1,30)\n",
    "            test_sim = np.append(test_sim, cos(output,target))\n",
    "    print('GAN_done')\n",
    "    \n",
    "    pred_GAN = np.where(test_sim < 0.95,1,0)\n",
    "    # pred EE\n",
    "    k = 0.002231531967748047\n",
    "    pred_EE, prob = get_pred_label_EE(EE, x, int(len(x)*k))\n",
    "    print('EE_done')\n",
    "    preds = pd.DataFrame(zip(pred_GAN, pred_EE))\n",
    "    preds.columns = ['pred_GAN', 'pred_EE']\n",
    "    return preds, preds.apply(mode,axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIeCgoSJGrRp"
   },
   "source": [
    "## Method 2. Auto Encoder + GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "We1bwhpjGiFt"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df = train_df.drop(columns=['ID'])\n",
    "train_df[\"ABS Amount\"] = train_df.abs().sum(1)\n",
    "train_df[\"Amount\"] = train_df.sum(1)\n",
    "val_df = pd.read_csv('val.csv')\n",
    "val_df = val_df.drop(columns=['ID'])\n",
    "val_df[\"ABS Amount\"] = val_df.abs().sum(1)\n",
    "val_df[\"Amount\"] = val_df.sum(1)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_df = test_df.drop(columns=['ID'])\n",
    "test_df[\"ABS Amount\"] = test_df.abs().sum(1)\n",
    "test_df[\"Amount\"] = test_df.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7Po6y52PGqKv"
   },
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "train = scaler.fit_transform(train_df)\n",
    "train = pd.DataFrame(train, columns = train_df.columns)\n",
    "val = scaler.transform(val_df.drop(columns = [\"Class\"]))\n",
    "val = pd.DataFrame(val, columns = [col for col in val_df.columns if col != \"Class\"])\n",
    "val[\"Class\"] = val_df[\"Class\"]\n",
    "test = scaler.transform(test_df)\n",
    "test = pd.DataFrame(test, columns = test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "y0Leq-8fFauZ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_size, z_size):\n",
    "    super().__init__()\n",
    "    self.linear1 = nn.Linear(input_size, 128)\n",
    "    self.linear2 = nn.Linear(128, 512)\n",
    "    self.linear3 = nn.Linear(512, z_size)\n",
    "    self.relu = nn.ReLU(True)\n",
    "        \n",
    "  def forward(self, real):\n",
    "    out = self.linear1(real)\n",
    "    out = self.relu(out)\n",
    "    out = self.linear2(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.linear3(out)\n",
    "    z = self.relu(out)\n",
    "    return z\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, z_size, output_size):\n",
    "    super().__init__()\n",
    "    self.linear1 = nn.Linear(z_size, 512)\n",
    "    self.linear2 = nn.Linear(512, 128)\n",
    "    self.linear3 = nn.Linear(128, output_size)\n",
    "    self.relu = nn.ReLU(True)\n",
    "        \n",
    "  def forward(self, z):\n",
    "    out = self.linear1(z)\n",
    "    out = self.relu(out)\n",
    "    out = self.linear2(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.linear3(out)\n",
    "    return out\n",
    "    \n",
    "class UsadModel(nn.Module):\n",
    "  def __init__(self, input_size, z_size):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(input_size, z_size)\n",
    "    self.decoder1 = Decoder(z_size, input_size)\n",
    "    self.decoder2 = Decoder(z_size, input_size)\n",
    "  \n",
    "  def training_step(self, batch, n):\n",
    "    z = self.encoder(batch)\n",
    "    w1 = self.decoder1(z)\n",
    "    w2 = self.decoder2(z)\n",
    "    w3 = self.decoder2(self.encoder(w1))\n",
    "    loss1 = 1/n*torch.mean((batch-w1)**2)+(1-1/n)*torch.mean((batch-w3)**2)\n",
    "    loss2 = 1/n*torch.mean((batch-w2)**2)-(1-1/n)*torch.mean((batch-w3)**2)\n",
    "    return loss1,loss2\n",
    "\n",
    "def training(epochs, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
    "    history = []\n",
    "    optimizer1 = opt_func(list(model.encoder.parameters())+list(model.decoder1.parameters()))\n",
    "    optimizer2 = opt_func(list(model.encoder.parameters())+list(model.decoder2.parameters()))\n",
    "    for epoch in range(epochs):\n",
    "        for [batch] in train_loader:\n",
    "            batch=to_device(batch,device)\n",
    "            \n",
    "            #Train AE1\n",
    "            loss1,loss2 = model.training_step(batch,epoch+1)\n",
    "            loss1.backward()\n",
    "            optimizer1.step()\n",
    "            optimizer1.zero_grad()\n",
    "            \n",
    "            \n",
    "            #Train AE2\n",
    "            loss1,loss2 = model.training_step(batch,epoch+1)\n",
    "            loss2.backward()\n",
    "            optimizer2.step()\n",
    "            optimizer2.zero_grad()\n",
    "\n",
    "        print(f\"Epoch : {epoch+1}\")\n",
    "        f1_score, threshold = calc_f1(model, val_loader)\n",
    "        torch.save(model.state_dict(), './usad_normal.pth', _use_new_zipfile_serialization=False)\n",
    "    return  threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ne2jxBcAFfyh"
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "RS9I23vWF0pM"
   },
   "outputs": [],
   "source": [
    "def calc_f1(model, val_loader):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    true = []\n",
    "    diffs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in iter(val_loader):\n",
    "            x = x.float().to(device)\n",
    "\n",
    "            _x = model.decoder1(model.encoder(x))\n",
    "            l1loss = nn.L1Loss(reduction = \"none\")\n",
    "            diff = l1loss(x, _x)\n",
    "            diff = torch.sum(diff, 1).cpu().numpy().tolist()\n",
    "            diffs.extend(diff)\n",
    "\n",
    "            # f1 score\n",
    "            true += y.tolist()\n",
    "    thresholds = []\n",
    "    f1_scores = []\n",
    "    for thr in np.linspace(0,100, 1000):\n",
    "      thresholds.append(thr)\n",
    "      pred = np.where(np.array(diffs)>thr, 1,0).tolist()\n",
    "      f1_scores.append(f1_score(true, pred, average='macro'))\n",
    "\n",
    "    max_f1 = max(f1_scores)\n",
    "    threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "    diffs = [[d] for d in diffs]\n",
    "    return max_f1, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EpGhIknGAKr",
    "outputId": "dde2c990-6003-4658-ccbe-1e9d428d4fb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "BATCH_SIZE =  256\n",
    "N_EPOCHS = 100\n",
    "input_size = 32\n",
    "z_size = 1024\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                                          data_utils.TensorDataset(torch.from_numpy(train.values).float()),\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=6\n",
    "                                          )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader( \n",
    "                                          data_utils.TensorDataset(torch.from_numpy(val.drop(columns=[\"Class\"]).values).float(), torch.from_numpy(val[\"Class\"].values).float()), \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=6\n",
    "                                          )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                                          data_utils.TensorDataset(torch.from_numpy(test.values).float()),\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, \n",
    "                                          num_workers=6\n",
    "                                          )\n",
    "\n",
    "model = UsadModel(input_size, z_size)\n",
    "model = to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJNN7p0ZGMcm",
    "outputId": "8c744e2f-7256-4296-f2e3-4f1abd62efb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100\n"
     ]
    }
   ],
   "source": [
    "threshold = training(N_EPOCHS,model,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "UDxpmEx2GPgk"
   },
   "outputs": [],
   "source": [
    "def prediction(model, thr, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    diffs = []\n",
    "    with torch.no_grad():\n",
    "        for [x] in iter(test_loader):\n",
    "\n",
    "            x = x.float().to(device)\n",
    "            _x = model.decoder1(model.encoder(x))\n",
    "            l1loss = nn.L1Loss(reduction = \"none\")\n",
    "            diff = l1loss(x, _x)\n",
    "            diff = torch.sum(diff, 1).cpu().numpy().tolist()\n",
    "            diffs.extend(diff)\n",
    "\n",
    "    pred = np.where(np.array(diffs)>thr, 1,0).tolist()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwhNTAf2GRG7",
    "outputId": "3eabae65-227c-4d4f-ba98-025fdd085201"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "preds = prediction(model, 1.4, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
