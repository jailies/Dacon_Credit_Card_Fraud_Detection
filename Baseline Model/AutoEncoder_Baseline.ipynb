{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
      "metadata": {
        "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1sbYGESQLYai",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sbYGESQLYai",
        "outputId": "153bb18f-9fe8-4e6a-8d36-cd04e2b1e760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
      "metadata": {
        "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.optim import Optimizer, AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR, CyclicLR, OneCycleLR\n",
        "#from transformers.optimization import get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "#from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 모델 학습을 위해 CUDA 환경 설정. : 지피유 설정\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "D4YXQkfxTJxO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4YXQkfxTJxO",
        "outputId": "6ad10613-d518-4bdf-9890-daaa27479bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
      "metadata": {
        "id": "fc7df3f2-62d0-4499-a46e-47d01699def0"
      },
      "source": [
        "## 하이퍼파라미터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
      "metadata": {
        "id": "c3367399-9798-4e38-967b-fd2320b9a2b2"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "LR = 1e-2\n",
        "BS = 16384 # 2의 제곱승꼴\n",
        "SEED = 41"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
      "metadata": {
        "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"
      },
      "source": [
        "## 시드고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
      "metadata": {
        "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
      "metadata": {
        "id": "05a4172e-5791-446f-9616-35c09d8bf25a"
      },
      "source": [
        "## 데이터로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
        "outputId": "34b0e5e9-6083-4b48-b050-feb2791797d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(113842, 30) (28462, 31) (142503, 30)\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv('./drive/MyDrive/신용카드 사기 데이콘/open/train.csv')\n",
        "train = train.drop(columns=['ID'])\n",
        "val = pd.read_csv('./drive/MyDrive/신용카드 사기 데이콘/open/val.csv')\n",
        "val = val.drop(columns=['ID'])\n",
        "test = pd.read_csv('./drive/MyDrive/신용카드 사기 데이콘/open/test.csv')\n",
        "test = test.drop(columns=['ID'])\n",
        "\n",
        "print(train.shape, val.shape, test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
      "metadata": {
        "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e"
      },
      "source": [
        "## 데이터셋 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
      "metadata": {
        "id": "16fd60a5-24e2-4539-bfd0-1c374a641699"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, eval_mode):\n",
        "        self.df = df\n",
        "        self.eval_mode = eval_mode\n",
        "        if self.eval_mode:\n",
        "            self.labels = self.df['Class'].values\n",
        "            self.df = self.df.drop(columns=['Class']).values\n",
        "        else:\n",
        "            self.df = self.df.values\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        if self.eval_mode:\n",
        "            x = torch.from_numpy(self.df[index]).type(torch.FloatTensor)\n",
        "            y = torch.FloatTensor([self.labels[index]])\n",
        "            return x, y\n",
        "            #self.x = self.df[index]\n",
        "            #self.y = self.labels[index]\n",
        "            #return torch.Tensor(self.x), self.y\n",
        "        else:\n",
        "            self.x = self.df[index]\n",
        "            return torch.Tensor(self.x)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9d880481-1965-499d-9caa-fdfa8526f789",
      "metadata": {
        "id": "9d880481-1965-499d-9caa-fdfa8526f789",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "548ef27b-7e92-44b3-8e02-03007d740af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_dataset = MyDataset(df=train, eval_mode=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=6)\n",
        "\n",
        "val_dataset = MyDataset(df = val, eval_mode=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39962463-032f-490a-a76d-c03991795f38",
      "metadata": {
        "id": "39962463-032f-490a-a76d-c03991795f38"
      },
      "source": [
        "## AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "QtSaUCRKqt6-",
      "metadata": {
        "id": "QtSaUCRKqt6-"
      },
      "outputs": [],
      "source": [
        "# 계층 정규화\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-5):\n",
        "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "        \"\"\"\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.variance_epsilon = eps\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.weight.data.fill_(1.0)\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon) # 계층정규화 완료\n",
        "        return self.weight * x + self.bias # wx+b\n",
        "        \n",
        "# 활성화 함수\n",
        "class GELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "        \n",
        "class AutoEncoder1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder1, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.ln = LayerNorm(5000)\n",
        "        self.ln1 = LayerNorm(3500)\n",
        "        self.ln2 = LayerNorm(2000)\n",
        "        self.ln3 = LayerNorm(1000)\n",
        "        \n",
        "        self.upblock1 = nn.Sequential(nn.Linear(30, 1000), nn.BatchNorm1d(1000),GELU())\n",
        "        self.upblock2 = nn.Sequential(nn.Linear(1000,2000), nn.BatchNorm1d(2000),GELU())\n",
        "        self.upblock3 = nn.Sequential(nn.Linear(2000,3500), nn.BatchNorm1d(3500),GELU())\n",
        "        self.upblock4 = nn.Sequential(nn.Linear(3500,5000), nn.BatchNorm1d(5000),GELU())\n",
        "\n",
        "        self.downblock1 = nn.Sequential(nn.Linear(5000, 3500),nn.BatchNorm1d(3500),GELU())\n",
        "        self.downblock2 = nn.Sequential(nn.Linear(3500, 2000),nn.BatchNorm1d(2000),GELU())\n",
        "        self.downblock3 = nn.Sequential(nn.Linear(2000, 1000),nn.BatchNorm1d(1000),GELU())\n",
        "        self.downblock4 = nn.Sequential(nn.Linear(1000, 300),nn.BatchNorm1d(300),GELU())\n",
        "        \n",
        "        self.fclayer = nn.Sequential(nn.Linear(300,30))\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        upblock1_out = self.upblock1(x) \n",
        "        upblock2_out = self.upblock2(upblock1_out)\n",
        "        upblock3_out = self.upblock3(upblock2_out)\n",
        "        upblock4_out = self.upblock4(upblock3_out)\n",
        "        \n",
        "        downblock1_out = self.downblock1(self.ln(upblock4_out)) \n",
        "        skipblock1 = downblock1_out + upblock3_out\n",
        "        downblock2_out = self.downblock2(self.ln1(skipblock1))\n",
        "        skipblock2 = downblock2_out + upblock2_out\n",
        "        downblock3_out = self.downblock3(self.ln2(skipblock2))\n",
        "        skipblock3 = downblock3_out + upblock1_out \n",
        "        downblock4_out = self.downblock4(self.ln3(skipblock3))\n",
        "        \n",
        "        x = self.fclayer(downblock4_out)\n",
        "         \n",
        "        return x # 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
      "metadata": {
        "id": "122af0aa-a1fd-4595-9488-35761e3cb596"
      },
      "source": [
        "## Train (학습)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
      "metadata": {
        "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "        # Loss Function\n",
        "        self.criterion = nn.L1Loss().to(self.device)\n",
        "        \n",
        "    def fit(self):\n",
        "        self.model.to(self.device)\n",
        "        best_score = 0\n",
        "        avg = 1\n",
        "        for epoch in range(EPOCHS):\n",
        "            self.model.train()\n",
        "            train_loss = []\n",
        "            for x in iter(self.train_loader):\n",
        "                x = x.float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                _x = self.model(x)\n",
        "                loss = self.criterion(x, _x)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                train_loss.append(loss.item())\n",
        "\n",
        "            score = self.validation(self.model, 0.95)\n",
        "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
        "\n",
        "            if self.scheduler is not None:\n",
        "                self.scheduler.step(score)\n",
        "\n",
        "            if best_score <= score and avg > np.mean(train_loss):\n",
        "                best_score = score\n",
        "                avg = np.mean(train_loss)\n",
        "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
        "                print('---------------------------')\n",
        "                print(f'Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
        "    \n",
        "    def validation(self, eval_model, thr):\n",
        "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "        eval_model.eval()\n",
        "        pred = []\n",
        "        true = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in iter(self.val_loader):\n",
        "                x = x.float().to(self.device)\n",
        "\n",
        "                _x = self.model(x)\n",
        "                diff = cos(x, _x).cpu().tolist()\n",
        "                batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n",
        "                pred += batch_pred\n",
        "                true += y.tolist()\n",
        "\n",
        "        return f1_score(true, pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
      "metadata": {
        "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24"
      },
      "source": [
        "## 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "jiqiaGRseZMI",
      "metadata": {
        "id": "jiqiaGRseZMI"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "86142d9a-68b7-4d04-8423-49d28025411d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86142d9a-68b7-4d04-8423-49d28025411d",
        "outputId": "511405cc-57c5-4f00-f258-ceeee5be7807",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : [0] Train loss : [0.5130279277052198] Val Score : [0.01770493016168002])\n",
            "---------------------------\n",
            "Train loss : [0.5130279277052198] Val Score : [0.01770493016168002])\n",
            "Epoch : [1] Train loss : [0.24230447198663438] Val Score : [0.28194988757013056])\n",
            "---------------------------\n",
            "Train loss : [0.24230447198663438] Val Score : [0.28194988757013056])\n",
            "Epoch : [2] Train loss : [0.1678751621927534] Val Score : [0.4936036828766804])\n",
            "---------------------------\n",
            "Train loss : [0.1678751621927534] Val Score : [0.4936036828766804])\n",
            "Epoch : [3] Train loss : [0.12744085384266718] Val Score : [0.5078749722988761])\n",
            "---------------------------\n",
            "Train loss : [0.12744085384266718] Val Score : [0.5078749722988761])\n",
            "Epoch : [4] Train loss : [0.10655226452010018] Val Score : [0.5133525205302055])\n",
            "---------------------------\n",
            "Train loss : [0.10655226452010018] Val Score : [0.5133525205302055])\n",
            "Epoch : [5] Train loss : [0.09226009781871523] Val Score : [0.5235793796094069])\n",
            "---------------------------\n",
            "Train loss : [0.09226009781871523] Val Score : [0.5235793796094069])\n",
            "Epoch : [6] Train loss : [0.08488902768918447] Val Score : [0.5463409410688171])\n",
            "---------------------------\n",
            "Train loss : [0.08488902768918447] Val Score : [0.5463409410688171])\n",
            "Epoch : [7] Train loss : [0.08307181085859026] Val Score : [0.5626898219704392])\n",
            "---------------------------\n",
            "Train loss : [0.08307181085859026] Val Score : [0.5626898219704392])\n",
            "Epoch : [8] Train loss : [0.07947085478476115] Val Score : [0.5723410221437316])\n",
            "---------------------------\n",
            "Train loss : [0.07947085478476115] Val Score : [0.5723410221437316])\n",
            "Epoch : [9] Train loss : [0.07559261896780559] Val Score : [0.5928085122313855])\n",
            "---------------------------\n",
            "Train loss : [0.07559261896780559] Val Score : [0.5928085122313855])\n",
            "Epoch : [10] Train loss : [0.07651270819561821] Val Score : [0.6361994777982936])\n",
            "Epoch : [11] Train loss : [0.07375070878437587] Val Score : [0.74464046996434])\n",
            "---------------------------\n",
            "Train loss : [0.07375070878437587] Val Score : [0.74464046996434])\n",
            "Epoch : [12] Train loss : [0.07247385382652283] Val Score : [0.8122361199071142])\n",
            "---------------------------\n",
            "Train loss : [0.07247385382652283] Val Score : [0.8122361199071142])\n",
            "Epoch : [13] Train loss : [0.06843897274562291] Val Score : [0.8422634702634115])\n",
            "---------------------------\n",
            "Train loss : [0.06843897274562291] Val Score : [0.8422634702634115])\n",
            "Epoch : [14] Train loss : [0.06446364734854017] Val Score : [0.856966968023358])\n",
            "---------------------------\n",
            "Train loss : [0.06446364734854017] Val Score : [0.856966968023358])\n",
            "Epoch : [15] Train loss : [0.06059042630451066] Val Score : [0.8844834793761085])\n",
            "---------------------------\n",
            "Train loss : [0.06059042630451066] Val Score : [0.8844834793761085])\n",
            "Epoch : [16] Train loss : [0.060428383627108166] Val Score : [0.890501890608512])\n",
            "---------------------------\n",
            "Train loss : [0.060428383627108166] Val Score : [0.890501890608512])\n",
            "Epoch : [17] Train loss : [0.059363351336547306] Val Score : [0.8967110829723166])\n",
            "---------------------------\n",
            "Train loss : [0.059363351336547306] Val Score : [0.8967110829723166])\n",
            "Epoch : [18] Train loss : [0.06083233441625323] Val Score : [0.8967110829723166])\n",
            "Epoch : [19] Train loss : [0.057174199393817356] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.057174199393817356] Val Score : [0.9097393418694286])\n",
            "Epoch : [20] Train loss : [0.0527727838073458] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.0527727838073458] Val Score : [0.9097393418694286])\n",
            "Epoch : [21] Train loss : [0.05180003706898008] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.05180003706898008] Val Score : [0.9097393418694286])\n",
            "Epoch : [22] Train loss : [0.05083702823945454] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.05083702823945454] Val Score : [0.9097393418694286])\n",
            "Epoch : [23] Train loss : [0.049515029681580405] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.049515029681580405] Val Score : [0.9097393418694286])\n",
            "Epoch : [24] Train loss : [0.048357757074492316] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.048357757074492316] Val Score : [0.9165787375726882])\n",
            "Epoch : [25] Train loss : [0.0466721983892577] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.0466721983892577] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.04602364929659026] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.04602364929659026] Val Score : [0.9165787375726882])\n",
            "Epoch : [27] Train loss : [0.045460677572659085] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.045460677572659085] Val Score : [0.9165787375726882])\n",
            "Epoch : [28] Train loss : [0.04673795348831585] Val Score : [0.9165787375726882])\n",
            "Epoch : [29] Train loss : [0.04610416612454823] Val Score : [0.9165787375726882])\n",
            "Epoch : [30] Train loss : [0.04542940642152514] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.04542940642152514] Val Score : [0.9165787375726882])\n",
            "Epoch : [31] Train loss : [0.04560396767088345] Val Score : [0.9165787375726882])\n",
            "Epoch : [32] Train loss : [0.04375702728118215] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.04375702728118215] Val Score : [0.9165787375726882])\n",
            "Epoch : [33] Train loss : [0.042681894664253504] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.042681894664253504] Val Score : [0.9165787375726882])\n",
            "Epoch : [34] Train loss : [0.04242427487458501] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.04242427487458501] Val Score : [0.9165787375726882])\n",
            "Epoch : [35] Train loss : [0.04252981022000313] Val Score : [0.9165787375726882])\n",
            "Epoch 00036: reducing learning rate of group 0 to 5.0000e-03.\n",
            "Epoch : [36] Train loss : [0.03552455987249102] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.03552455987249102] Val Score : [0.9165787375726882])\n",
            "Epoch : [37] Train loss : [0.03337619294013296] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.03337619294013296] Val Score : [0.9165787375726882])\n",
            "Epoch : [38] Train loss : [0.03226471905197416] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.03226471905197416] Val Score : [0.9165787375726882])\n",
            "Epoch : [39] Train loss : [0.03306991447295461] Val Score : [0.9165787375726882])\n",
            "Epoch : [40] Train loss : [0.031675475516489575] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.031675475516489575] Val Score : [0.9165787375726882])\n",
            "Epoch : [41] Train loss : [0.03192164083676679] Val Score : [0.9165787375726882])\n",
            "Epoch : [42] Train loss : [0.03194729850760528] Val Score : [0.9165787375726882])\n",
            "Epoch : [43] Train loss : [0.03200118403349604] Val Score : [0.9165787375726882])\n",
            "Epoch : [44] Train loss : [0.03185368808252471] Val Score : [0.9165787375726882])\n",
            "Epoch : [45] Train loss : [0.03269534318574837] Val Score : [0.9165787375726882])\n",
            "Epoch : [46] Train loss : [0.03273581713438034] Val Score : [0.9165787375726882])\n",
            "Epoch 00047: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [47] Train loss : [0.0290720739534923] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.0290720739534923] Val Score : [0.9165787375726882])\n",
            "Epoch : [48] Train loss : [0.027990567897047316] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.027990567897047316] Val Score : [0.9165787375726882])\n",
            "Epoch : [49] Train loss : [0.027016574250800268] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.027016574250800268] Val Score : [0.9165787375726882])\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "model = nn.DataParallel(AutoEncoder1())\n",
        "model.eval()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
        "trainer.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "CXGFu4gSkaDY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CXGFu4gSkaDY",
        "outputId": "045de4b4-ee96-4019-92da-94cfd6f0e2ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |     815 MB |   11698 MB |   16319 GB |   16318 GB |\\n|       from large pool |     813 MB |   11694 MB |   16312 GB |   16311 GB |\\n|       from small pool |       1 MB |       3 MB |       7 GB |       7 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |     815 MB |   11698 MB |   16319 GB |   16318 GB |\\n|       from large pool |     813 MB |   11694 MB |   16312 GB |   16311 GB |\\n|       from small pool |       1 MB |       3 MB |       7 GB |       7 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   12040 MB |   12040 MB |   12040 MB |       0 B  |\\n|       from large pool |   12036 MB |   12036 MB |   12036 MB |       0 B  |\\n|       from small pool |       4 MB |       4 MB |       4 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  243952 KB |    1359 MB |    2520 GB |    2519 GB |\\n|       from large pool |  243919 KB |    1358 MB |    2504 GB |    2503 GB |\\n|       from small pool |      33 KB |       2 MB |      16 GB |      16 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     192    |     290    |  213000    |  212808    |\\n|       from large pool |      28    |     102    |  127271    |  127243    |\\n|       from small pool |     164    |     192    |   85729    |   85565    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     192    |     290    |  213000    |  212808    |\\n|       from large pool |      28    |     102    |  127271    |  127243    |\\n|       from small pool |     164    |     192    |   85729    |   85565    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      74    |      74    |      74    |       0    |\\n|       from large pool |      72    |      72    |      72    |       0    |\\n|       from small pool |       2    |       2    |       2    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      11    |      74    |  116859    |  116848    |\\n|       from large pool |       9    |      69    |   81224    |   81215    |\\n|       from small pool |       2    |      12    |   35635    |   35633    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41ee1a4c-afe9-4f3c-a3f6-3bca5eb2109f",
      "metadata": {
        "id": "41ee1a4c-afe9-4f3c-a3f6-3bca5eb2109f"
      },
      "source": [
        "## 추론"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c53e6313-382b-4f31-a587-1824c579abb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c53e6313-382b-4f31-a587-1824c579abb7",
        "outputId": "1aa3a5db-c396-4bc8-c72d-f30eff4d1a46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): AutoEncoder1(\n",
              "    (ln): LayerNorm()\n",
              "    (ln1): LayerNorm()\n",
              "    (ln2): LayerNorm()\n",
              "    (ln3): LayerNorm()\n",
              "    (upblock1): Sequential(\n",
              "      (0): Linear(in_features=30, out_features=1000, bias=True)\n",
              "      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (upblock2): Sequential(\n",
              "      (0): Linear(in_features=1000, out_features=2000, bias=True)\n",
              "      (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (upblock3): Sequential(\n",
              "      (0): Linear(in_features=2000, out_features=3500, bias=True)\n",
              "      (1): BatchNorm1d(3500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (upblock4): Sequential(\n",
              "      (0): Linear(in_features=3500, out_features=5000, bias=True)\n",
              "      (1): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (downblock1): Sequential(\n",
              "      (0): Linear(in_features=5000, out_features=3500, bias=True)\n",
              "      (1): BatchNorm1d(3500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (downblock2): Sequential(\n",
              "      (0): Linear(in_features=3500, out_features=2000, bias=True)\n",
              "      (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (downblock3): Sequential(\n",
              "      (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
              "      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (downblock4): Sequential(\n",
              "      (0): Linear(in_features=1000, out_features=300, bias=True)\n",
              "      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (fclayer): Sequential(\n",
              "      (0): Linear(in_features=300, out_features=30, bias=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model = AutoEncoder1()\n",
        "model.load_state_dict(torch.load('./best_model.pth'))\n",
        "model = nn.DataParallel(model)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "65628d5a-dedd-4525-8f9d-ba3f00de9eee",
      "metadata": {
        "id": "65628d5a-dedd-4525-8f9d-ba3f00de9eee"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('./drive/MyDrive/신용카드 사기 데이콘/open/test.csv')\n",
        "test = test.drop(columns=['ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e87c859b-be5a-426b-8a02-08ff5b38f1bc",
      "metadata": {
        "id": "e87c859b-be5a-426b-8a02-08ff5b38f1bc"
      },
      "outputs": [],
      "source": [
        "test_dataset = MyDataset(test, False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "82bb801c-9207-4e2d-a44e-1b86eab8ff6e",
      "metadata": {
        "id": "82bb801c-9207-4e2d-a44e-1b86eab8ff6e"
      },
      "outputs": [],
      "source": [
        "def prediction(model, thr, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for x in iter(test_loader):\n",
        "            x = x.float().to(device)\n",
        "            _x = model(x)\n",
        "            \n",
        "            diff = cos(x, _x).cpu().tolist()\n",
        "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
        "            pred += batch_pred\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6d85fcc2-a3a7-451c-878f-8a0bb105c4cf",
      "metadata": {
        "id": "6d85fcc2-a3a7-451c-878f-8a0bb105c4cf"
      },
      "outputs": [],
      "source": [
        "preds = prediction(model, 0.95, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7ff9df77-6591-441d-a4ce-1a0aacc8f8df",
      "metadata": {
        "id": "7ff9df77-6591-441d-a4ce-1a0aacc8f8df"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv('./drive/MyDrive/신용카드 사기 데이콘/open/sample_submission.csv')\n",
        "submit['Class'] = preds\n",
        "submit.to_csv('./drive/MyDrive/신용카드 사기 데이콘/open/submit_autoencoder2.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}